{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model to decode sequences of digits from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 31732 31732\n",
      "validation: 1670 1670\n",
      "test: 13068 13068\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(133)\n",
    "\n",
    "def load_data(file_name,valid_size=0):\n",
    "     with open(file_name, 'r') as f:\n",
    "        data=pickle.load(f)\n",
    "        labels=data[\"label\"]\n",
    "        images=data[\"image\"]\n",
    "        if valid_size:\n",
    "            all_data=zip(images,labels)\n",
    "            np.random.shuffle(all_data)\n",
    "            valid_data=all_data[:valid_size]\n",
    "            valid_images,valid_labels=tuple([list(l) for l in zip(*valid_data)])\n",
    "            train_data=all_data[valid_size:]\n",
    "            train_images,train_labels=tuple([list(l) for l in zip(*train_data)])\n",
    "            return train_images,train_labels,valid_images,valid_labels\n",
    "        return images,labels\n",
    "valid_size=1670 #about 5% of the data\n",
    "train_images,train_labels,valid_images,valid_labels=load_data(\"train.pickle\",valid_size)\n",
    "test_images,test_labels=load_data(\"test.pickle\")\n",
    "print(\"train:\",len(train_images),len(train_labels))\n",
    "print(\"validation:\",len(valid_images),len(valid_labels))\n",
    "print(\"test:\",len(test_images),len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img size:  3072\n",
      "labels:  [  1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.]\n",
      "5.0 reshaped:  [[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]]\n",
      "printed labels:  ['1', '2', '3', '4', '5', '6', '7', '8', '9', '0', ' ']\n",
      "blanc label 11.0\n",
      "blanc label reshaped [[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]] (1, 11)\n",
      "blanc label reduced : 11.0\n"
     ]
    }
   ],
   "source": [
    "img_size=32*32*3\n",
    "distinct_labels=np.arange(1,12).astype(np.float32) # 11 reprsents no more digit\n",
    "distinct_labels_size=len(distinct_labels)\n",
    "blanc_label=distinct_labels[distinct_labels_size-1]\n",
    "\n",
    "def reshape_image(image):\n",
    "    return np.reshape(image,(1,img_size)).astype(np.float32)\n",
    "\n",
    "def reshape_label(label):\n",
    "    return np.reshape((distinct_labels==label),(1,distinct_labels_size)).astype(np.float32)\n",
    "\n",
    "def reduce_label(reshaped_label):\n",
    "    return np.sum(np.multiply(np.transpose(reshaped_label[0]),distinct_labels))\n",
    "\n",
    "def print_label(label):\n",
    "    if label==10.:\n",
    "        return \"0\"\n",
    "    elif label==11.0:\n",
    "        return \" \"\n",
    "    return str(int(label))\n",
    "\n",
    "print(\"img size: \",img_size)\n",
    "print(\"labels: \",distinct_labels)\n",
    "print(\"5.0 reshaped: \",reshape_label(5.0))\n",
    "print(\"printed labels: \",[print_label(i) for i in distinct_labels])\n",
    "print(\"blanc label\",blanc_label)\n",
    "reshaped_blanc_label=reshape_label(blanc_label)\n",
    "print(\"blanc label reshaped\",reshaped_blanc_label,reshaped_blanc_label.shape)\n",
    "print(\"blanc label reduced :\",reduce_label(reshaped_blanc_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expanding train data\n",
      "initial size:  31732 31732\n",
      "0%.........1%.........3%.........4%.........6%.........7%.........9%.........11%.........12%.........14%.........15%.........17%.........18%.........20%.........22%.........23%.........25%.........26%.........28%.........29%.........31%.........33%.........34%.........36%.........37%.........39%.........40%.........42%.........44%.........45%.........47%.........48%.........50%.........51%.........53%.........55%.........56%.........58%.........59%.........61%.........63%.........64%.........66%.........67%.........69%.........70%.........72%.........74%.........75%.........77%.........78%.........80%.........81%.........83%.........85%.........86%.........88%.........89%.........91%.........92%.........94%.........96%.........97%.........99%....transformed size:  101331 101331\n",
      "expanding valid data\n",
      "initial size:  1670 1670\n",
      "0%.........29%.........59%.........89%...transformed size:  5328 5328\n",
      "expanding test data\n",
      "initial size:  13068 13068\n",
      "0%.........3%.........7%.........11%.........15%.........19%.........22%.........26%.........30%.........34%.........38%.........42%.........45%.........49%.........53%.........57%.........61%.........65%.........68%.........72%.........76%.........80%.........84%.........88%.........91%.........95%.........99%.transformed size:  39100 39100\n"
     ]
    }
   ],
   "source": [
    "#we can choose to expand only a subset of the data for the next steps\n",
    "train_subset = len(train_images)\n",
    "valid_subset=len(valid_images)\n",
    "test_subset=len(test_images)\n",
    "\n",
    "def expand_image(image,image_labels):\n",
    "    \"\"\"expand the image to have one instance for each digit\"\"\"  \n",
    "    reshaped_images = list()\n",
    "    reshaped_labels=list()\n",
    "    reshaped_image=reshape_image(image)\n",
    "    image_labels=image_labels+[blanc_label]#the last prediction should be blanc label\n",
    "    for image_label in image_labels:\n",
    "        reshaped_images.append(reshaped_image)\n",
    "        reshaped_labels.append(reshape_label(image_label))\n",
    "    return reshaped_images,reshaped_labels\n",
    "    \n",
    "def expand_data(images,labels):\n",
    "    \"\"\"expand the images to have one instance for each digit\"\"\"\n",
    "    print(\"initial size: \",len(images),len(labels))\n",
    "    expanded_images=list()\n",
    "    expanded_labels=list()\n",
    "    total_images=len(images)\n",
    "    image_index=-1\n",
    "    for image,image_labels in zip(images,labels):  \n",
    "        image_index=image_index+1\n",
    "        reshaped_images,reshaped_labels=expand_image(image,image_labels)\n",
    "        expanded_images.extend(reshaped_images)\n",
    "        expanded_labels.extend(reshaped_labels)\n",
    "        if image_index % 500 == 0:\n",
    "            percent=image_index*100/total_images\n",
    "            sys.stdout.write(\"%d%%\" % percent)\n",
    "            sys.stdout.flush()\n",
    "        elif image_index % 50 == 0:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "    print(\"transformed size: \",len(expanded_images),len(expanded_labels))\n",
    "    return expanded_images,expanded_labels\n",
    "    \n",
    "print(\"expanding train data\")\n",
    "expanded_train_data,expanded_train_labels=expand_data(train_images[:train_subset],train_labels[:train_subset])\n",
    "print(\"expanding valid data\")\n",
    "expanded_valid_data,expanded_valid_labels=expand_data(valid_images[:valid_subset],valid_labels[:valid_subset])\n",
    "print(\"expanding test data\")\n",
    "expanded_test_data,expanded_test_labels=expand_data(test_images[:test_subset],test_labels[:test_subset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class IndexGenerator(object):\n",
    "    \"\"\"generates the next index of the data from wich we can take a subset of length batch_size\"\"\"\n",
    "    def __init__(self, labels, batch_size):\n",
    "        self._index=0\n",
    "        self._labels=labels\n",
    "        self._length=len(labels)\n",
    "        self._batch_size=batch_size\n",
    "    def _next(self):\n",
    "        curr_index=self._index\n",
    "        self._index=self._index+self._batch_size\n",
    "        #make sure we are at the starting of an image (just after a blank label)\n",
    "        while self._index < self._length and reduce_label(self._labels[self._index-1])!=blanc_label:\n",
    "            self._index=self._index+1\n",
    "        if self._index+self._batch_size > self._length:\n",
    "            self._index=0\n",
    "        #if(curr_index!=0):\n",
    "        #    print(self._labels[curr_index-1],self._labels[curr_index])\n",
    "        return curr_index\n",
    "        \n",
    "train_batch_size=128\n",
    "valid_batch_size=128\n",
    "test_batch_size=128\n",
    "train_index_generator=IndexGenerator(expanded_train_labels,train_batch_size)\n",
    "valid_index_generator=IndexGenerator(expanded_valid_labels,valid_batch_size)\n",
    "test_index_generator=IndexGenerator(expanded_test_labels,test_batch_size)\n",
    "#print(\"train indexes:\",train_index_generator._next(),train_index_generator._next(),train_index_generator._next(),train_index_generator._next())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer\n"
     ]
    }
   ],
   "source": [
    "num_nodes = 64\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Parameters:\n",
    "    # Input gate: input, previous output, and bias.\n",
    "    ix = tf.Variable(tf.truncated_normal([img_size, num_nodes], stddev=0.1))\n",
    "    im = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], stddev=0.1))\n",
    "    ib = tf.Variable(tf.ones([1, num_nodes]))\n",
    "    # Forget gate: input, previous output, and bias.\n",
    "    fx = tf.Variable(tf.truncated_normal([img_size, num_nodes], stddev=0.1))\n",
    "    fm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], stddev=0.1))\n",
    "    fb = tf.Variable(tf.ones([1, num_nodes]))\n",
    "    # Memory cell: input, state and bias.                     \n",
    "    cx = tf.Variable(tf.truncated_normal([img_size, num_nodes], stddev=0.1))\n",
    "    cm = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], stddev=0.1))\n",
    "    cb = tf.Variable(tf.ones([1, num_nodes]))\n",
    "    # Output gate: input, previous output, and bias.\n",
    "    ox = tf.Variable(tf.truncated_normal([img_size, num_nodes], stddev=0.1))\n",
    "    om = tf.Variable(tf.truncated_normal([num_nodes, num_nodes], stddev=0.1))\n",
    "    ob = tf.Variable(tf.ones([1, num_nodes]))\n",
    "    \n",
    "    \n",
    "    # Classifier weights and biases.\n",
    "    weights = tf.Variable(tf.truncated_normal([num_nodes, distinct_labels_size], stddev=0.1))\n",
    "    biases = tf.Variable(tf.ones([distinct_labels_size]))\n",
    "        \n",
    "    # Definition of the cell computation.\n",
    "    \n",
    "    def lstm_cell(i, o, state):\n",
    "        \"\"\"Create a LSTM cell. See e.g.: http://arxiv.org/pdf/1402.1128v1.pdf\n",
    "        Note that in this formulation, we omit the various connections between the\n",
    "        previous state and the gates.\"\"\"        \n",
    "        input_gate = tf.sigmoid(tf.matmul(i, ix) + tf.matmul(o, im) + ib)        \n",
    "        forget_gate = tf.sigmoid(tf.matmul(i, fx) + tf.matmul(o, fm) + fb)\n",
    "        update = tf.matmul(i, cx) + tf.matmul(o, cm) + cb\n",
    "        state = forget_gate * state + input_gate * tf.tanh(update)\n",
    "        output_gate = tf.sigmoid(tf.matmul(i, ox) + tf.matmul(o, om) + ob)\n",
    "        return output_gate * tf.tanh(state), state\n",
    "    \n",
    "    initial_output = tf.Variable(tf.zeros([1, num_nodes]), trainable=False)\n",
    "    initial_state = tf.Variable(tf.zeros([1, num_nodes]), trainable=False)\n",
    "    \n",
    "    tf_blanc_label=tf.constant(reshape_label(blanc_label))\n",
    "    \n",
    "    def lstm_cell_data(input_data,input_labels):\n",
    "        outputs=list()\n",
    "        output=initial_output\n",
    "        state=initial_state\n",
    "        for i,label in zip(input_data,input_labels):\n",
    "            output, state = lstm_cell(i, output, state)\n",
    "            outputs.append(output)\n",
    "            #reinitialize the state in cass of end of image\n",
    "            is_blanc_label=tf.reduce_all(tf.equal(tf_blanc_label,label))\n",
    "            output=tf.cond(is_blanc_label,lambda :initial_output, lambda :output)\n",
    "            #output=tf.Print(output,[is_blanc_label,label,tf_blanc_label],message=\"Blanc\")\n",
    "            state=tf.cond(is_blanc_label,lambda :initial_state, lambda :state)\n",
    "        return outputs\n",
    "       \n",
    "    def model(data):\n",
    "        \"\"\"model the data\"\"\"\n",
    "        return tf.matmul(data,weights)+biases\n",
    "    \n",
    "    def make_place_holder_list(size,shape,name):\n",
    "        place_holder_list=list()\n",
    "        for i in range(size):\n",
    "            place_holder_list.append(tf.placeholder(tf.float32, shape=shape,name=name+\"_\"+str(i)))\n",
    "        return place_holder_list\n",
    "            \n",
    "    tf_train_data=make_place_holder_list(train_batch_size,[1,img_size],\"tf_train_data\")\n",
    "    tf_train_labels=make_place_holder_list(train_batch_size,[1,distinct_labels_size],\"tf_train_labels\")\n",
    "    tf_valid_data=make_place_holder_list(valid_batch_size,[1,img_size],\"tf_valid_data\")\n",
    "    tf_valid_labels=make_place_holder_list(valid_batch_size,[1,distinct_labels_size],\"tf_valid_labels\")\n",
    "    tf_test_data=make_place_holder_list(test_batch_size,[1,img_size],\"tf_test_data\")\n",
    "    tf_test_labels=make_place_holder_list(test_batch_size,[1,distinct_labels_size],\"tf_test_labels\")\n",
    "    \n",
    "    tf_train_outputs=lstm_cell_data(tf_train_data,tf_train_labels)\n",
    "    tf_valid_outputs=lstm_cell_data(tf_valid_data,tf_valid_labels)\n",
    "    tf_test_outputs=lstm_cell_data(tf_test_data,tf_test_labels)\n",
    "    \n",
    "    # Classifier.\n",
    "    tf_used_labels=tf.concat(0,tf_train_labels)\n",
    "    logits = model(tf.concat(0,tf_train_outputs))\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits, tf_used_labels))\n",
    "        \n",
    "    # Optimizer.\n",
    "    print(\"optimizer\")\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions.\n",
    "    train_prediction=tf.nn.softmax(logits)\n",
    "    valid_prediction=tf.nn.softmax(model(tf.concat(0,tf_valid_outputs)))\n",
    "    test_prediction=tf.nn.softmax(model(tf.concat(0,tf_test_outputs)))\n",
    "  \n",
    "  # Sampling and validation eval: batch 1, no unrolling.TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Loss at step 0: 2.311051\n",
      "Training accuracy: 14.1%\n",
      "Validation accuracy: 30.5%\n",
      "Loss at step 100: 2.093442\n",
      "Training accuracy: 42.2%\n",
      "Validation accuracy: 32.0%\n",
      "Loss at step 200: 2.040813\n",
      "Training accuracy: 30.5%\n",
      "Validation accuracy: 43.0%\n",
      "Loss at step 300: 1.990390\n",
      "Training accuracy: 41.4%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 400: 2.038884\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 500: 2.082335\n",
      "Training accuracy: 35.2%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 600: 2.023972\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 700: 1.919177\n",
      "Training accuracy: 46.9%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 800: 1.924898\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 900: 2.018118\n",
      "Training accuracy: 41.4%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 1000: 1.992486\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 1100: 1.972295\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 1200: 1.977157\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 43.0%\n",
      "Loss at step 1300: 1.964125\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 1400: 1.915965\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 1500: 1.951592\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 1600: 1.945673\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 1700: 1.927988\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 1800: 1.977141\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 1900: 1.892858\n",
      "Training accuracy: 41.4%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 2000: 1.910061\n",
      "Training accuracy: 42.2%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 2100: 1.906538\n",
      "Training accuracy: 42.2%\n",
      "Validation accuracy: 43.0%\n",
      "Loss at step 2200: 1.902790\n",
      "Training accuracy: 44.5%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 2300: 1.913661\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 2400: 1.910495\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 2500: 1.951841\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 2600: 1.964863\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 2700: 1.931576\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 2800: 1.945880\n",
      "Training accuracy: 44.5%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 2900: 1.896538\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 3000: 1.934041\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 3100: 1.959314\n",
      "Training accuracy: 36.7%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 3200: 1.932304\n",
      "Training accuracy: 37.5%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 3300: 1.947288\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 3400: 1.972562\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 35.9%\n",
      "Loss at step 3500: 1.907431\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 3600: 1.926720\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 3700: 1.900843\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 3800: 1.918084\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 3900: 1.990927\n",
      "Training accuracy: 35.9%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 4000: 1.966806\n",
      "Training accuracy: 37.5%\n",
      "Validation accuracy: 43.8%\n",
      "Loss at step 4100: 1.897352\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 4200: 1.856556\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 4300: 1.882484\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 4400: 1.911751\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 4500: 1.871740\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 4600: 1.908306\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 4700: 1.895325\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 4800: 1.941076\n",
      "Training accuracy: 36.7%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 4900: 1.914758\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 5000: 1.891421\n",
      "Training accuracy: 41.4%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 5100: 1.906844\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 5200: 1.862167\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 5300: 1.920685\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 43.0%\n",
      "Loss at step 5400: 1.876577\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 5500: 1.894222\n",
      "Training accuracy: 43.8%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 5600: 1.843722\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 5700: 1.834203\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 5800: 1.916925\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 5900: 1.842493\n",
      "Training accuracy: 37.5%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 6000: 1.966044\n",
      "Training accuracy: 34.4%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 6100: 1.931800\n",
      "Training accuracy: 42.2%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 6200: 1.905381\n",
      "Training accuracy: 35.2%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 6300: 1.885221\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 6400: 1.850566\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 6500: 1.983360\n",
      "Training accuracy: 37.5%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 6600: 1.857675\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 6700: 1.968474\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 6800: 1.883770\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 6900: 1.863381\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 7000: 1.906687\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 7100: 1.899540\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 7200: 1.887720\n",
      "Training accuracy: 37.5%\n",
      "Validation accuracy: 35.9%\n",
      "Loss at step 7300: 1.916984\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 7400: 1.867892\n",
      "Training accuracy: 42.2%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 7500: 1.928543\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 35.9%\n",
      "Loss at step 7600: 1.826421\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 7700: 1.973817\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 7800: 1.884065\n",
      "Training accuracy: 43.0%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 7900: 1.920402\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 8000: 1.809587\n",
      "Training accuracy: 43.8%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 8100: 1.822928\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 8200: 1.899014\n",
      "Training accuracy: 36.7%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 8300: 1.881578\n",
      "Training accuracy: 37.5%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 8400: 1.915470\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 8500: 1.855900\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 37.5%\n",
      "Loss at step 8600: 1.931248\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 8700: 1.928908\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 8800: 1.858029\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 8900: 1.867605\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 36.7%\n",
      "Loss at step 9000: 1.898432\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 9100: 1.820509\n",
      "Training accuracy: 42.2%\n",
      "Validation accuracy: 41.4%\n",
      "Loss at step 9200: 1.871738\n",
      "Training accuracy: 39.1%\n",
      "Validation accuracy: 40.6%\n",
      "Loss at step 9300: 1.893545\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.8%\n",
      "Loss at step 9400: 1.848941\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 43.0%\n",
      "Loss at step 9500: 1.883610\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 9600: 1.907434\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 9700: 1.857191\n",
      "Training accuracy: 39.8%\n",
      "Validation accuracy: 38.3%\n",
      "Loss at step 9800: 1.925964\n",
      "Training accuracy: 35.9%\n",
      "Validation accuracy: 39.1%\n",
      "Loss at step 9900: 1.868578\n",
      "Training accuracy: 40.6%\n",
      "Validation accuracy: 42.2%\n",
      "Loss at step 10000: 1.971414\n",
      "Training accuracy: 38.3%\n",
      "Validation accuracy: 38.3%\n",
      "testation accuracy: 41.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10001\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    predictions=np.reshape(np.array(predictions),(-1,distinct_labels_size)).astype(np.float32)\n",
    "    labels=np.reshape(np.array(labels),(-1,distinct_labels_size)).astype(np.float32)\n",
    "    #print(predictions.shape,labels.shape)\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "            / predictions.shape[0])\n",
    "\n",
    "def populate_feed_dict(feed_dict,data,labels,index,size,data_variable,labels_variable):\n",
    "    for i in range(size):\n",
    "        feed_dict[data_variable[i]] = data[index+i]\n",
    "        feed_dict[labels_variable[i]] = labels[index+i]\n",
    "    return feed_dict\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        train_index=train_index_generator._next()\n",
    "        feed_dict=populate_feed_dict(dict(),expanded_train_data,expanded_train_labels,train_index,\n",
    "                                     train_batch_size,tf_train_data,tf_train_labels)\n",
    "        _, l, predictions,used_labels = session.run([optimizer, loss, train_prediction,tf_used_labels],feed_dict=feed_dict)\n",
    "        if (step % 100 == 0):\n",
    "            labels=expanded_train_labels[train_index:train_index+train_batch_size]\n",
    "            print('Loss at step %d: %f' % (step, l))\n",
    "            print('Training accuracy: %.1f%%' % accuracy(\n",
    "                    predictions, labels))\n",
    "            #print('Verifying acuracy, accuracy: %.1f%%' % accuracy(\n",
    "            #        used_labels, labels))\n",
    "            # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "            # just to get that one numpy array. Note that it recomputes all its graph\n",
    "            # dependencies\n",
    "            valid_index=valid_index_generator._next()\n",
    "            feed_dict=populate_feed_dict(dict(),expanded_valid_data,expanded_valid_labels,valid_index,\n",
    "                                     valid_batch_size,tf_valid_data,tf_valid_labels)\n",
    "            valid_labels=expanded_valid_labels[valid_index:valid_index+valid_batch_size]\n",
    "            print('Validation accuracy: %.1f%%' % accuracy(\n",
    "                    session.run([valid_prediction],feed_dict=feed_dict),valid_labels))\n",
    "            \n",
    "    test_index=test_index_generator._next()\n",
    "    feed_dict=populate_feed_dict(dict(),expanded_test_data,expanded_test_labels,test_index,\n",
    "                                         test_batch_size,tf_test_data,tf_test_labels)\n",
    "    test_labels=expanded_test_labels[test_index:test_index+test_batch_size]\n",
    "    print('testation accuracy: %.1f%%' % accuracy(\n",
    "            session.run([test_prediction],feed_dict=feed_dict),test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d in module tensorflow.python.ops.gen_nn_ops:\n",
      "\n",
      "conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)\n",
      "    Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
      "    \n",
      "    Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
      "    and a filter / kernel tensor of shape\n",
      "    `[filter_height, filter_width, in_channels, out_channels]`, this op\n",
      "    performs the following:\n",
      "    \n",
      "    1. Flattens the filter to a 2-D matrix with shape\n",
      "       `[filter_height * filter_width * in_channels, output_channels]`.\n",
      "    2. Extracts image patches from the input tensor to form a *virtual*\n",
      "       tensor of shape `[batch, out_height, out_width,\n",
      "       filter_height * filter_width * in_channels]`.\n",
      "    3. For each patch, right-multiplies the filter matrix and the image patch\n",
      "       vector.\n",
      "    \n",
      "    In detail, with the default NHWC format,\n",
      "    \n",
      "        output[b, i, j, k] =\n",
      "            sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] *\n",
      "                            filter[di, dj, q, k]\n",
      "    \n",
      "    Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
      "    horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types: `float32`, `float64`.\n",
      "      filter: A `Tensor`. Must have the same type as `input`.\n",
      "      strides: A list of `ints`.\n",
      "        1-D of length 4.  The stride of the sliding window for each dimension\n",
      "        of `input`. Must be in the same order as the dimension specified with format.\n",
      "      padding: A `string` from: `\"SAME\", \"VALID\"`.\n",
      "        The type of padding algorithm to use.\n",
      "      use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "      data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`. Defaults to `\"NHWC\"`.\n",
      "        Specify the data format of the input and output data. With the\n",
      "        default format \"NHWC\", the data is stored in the order of:\n",
      "            [batch, in_height, in_width, in_channels].\n",
      "        Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "            [batch, in_channels, in_height, in_width].\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Some tensor we want to print the value of\n",
    "a = tf.constant([1.0, 3.0])\n",
    "\n",
    "# Add print operation\n",
    "a = tf.Print(a, [a],message=\"printing a\")\n",
    "\n",
    "# Add more elements of the graph using a\n",
    "b = tf.add(a, a).eval()\n",
    "print(a.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(tf.Print)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
