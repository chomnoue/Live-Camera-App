{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data from [Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage,misc\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "import h5py\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "last_percent_reported = None\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 1% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "        \n",
    "def maybe_download(filename, expected_bytes, force=False):\n",
    "  \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
    "  if force or not os.path.exists(filename):\n",
    "    print('Attempting to download:', filename) \n",
    "    filename, _ = urlretrieve(url + filename, filename, reporthook=download_progress_hook)\n",
    "    print('\\nDownload Complete!')\n",
    "  statinfo = os.stat(filename)\n",
    "  if statinfo.st_size == expected_bytes:\n",
    "    print('Found and verified', filename)\n",
    "  else:\n",
    "    raise Exception(\n",
    "      'Failed to verify ' + filename + '. Can you get to it with a browser?')\n",
    "  return filename\n",
    "\n",
    "train_filename = maybe_download('train.tar.gz', 404141560)\n",
    "test_filename = maybe_download('test.tar.gz', 276555967)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(133)\n",
    "\n",
    "def maybe_extract(filename, force=False):\n",
    "  root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "  if os.path.isdir(root) and not force:\n",
    "    # You may override by setting force=True.\n",
    "    print('%s already present - Skipping extraction of %s.' % (root, filename))\n",
    "  else:\n",
    "    print('Extracting data for %s. This may take a while. Please wait.' % root)\n",
    "    tar = tarfile.open(filename)\n",
    "    sys.stdout.flush()\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "  nb_files = len([\n",
    "    file_name for file_name in sorted(os.listdir(root))\n",
    "    if file_name.endswith(\".png\")])\n",
    "  print(\"found %d image files in %s\" % (nb_files,root))\n",
    "  return root\n",
    "  \n",
    "train_folder = maybe_extract(train_filename)\n",
    "test_folder = maybe_extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_sample_images(folder,to_display=5):\n",
    "    print(\"displaying %d sample images from folder %s\" %(to_display,folder))\n",
    "    images=[file_name for file_name in sorted(os.listdir(folder)) \n",
    "            if file_name.endswith(\".png\")]\n",
    "    for image in np.random.choice(images,to_display):\n",
    "        print(image)\n",
    "        display(Image(os.path.join(folder, image)))\n",
    "\n",
    "display_sample_images(train_folder,2)\n",
    "display_sample_images(test_folder,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data in a more manageable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "image_size = 64  # Pixel width and height.\n",
    "num_channels=3\n",
    "sub_image_size=54\n",
    "max_labels=6\n",
    "blanc_label=10\n",
    "\n",
    "final_image_size=32\n",
    "blanc_label=10\n",
    "\n",
    "def display_image(image):\n",
    "    plt.figure()\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def expand(min_,max_,ratio,maximum):\n",
    "    dist=math.ceil((max_-min_)*ratio)\n",
    "    min_=int(min_-dist)\n",
    "    max_=int(max_+dist)\n",
    "    return max(min_,0),min(max_,maximum)\n",
    "\n",
    "def load_folder(folder, min_num_images,to_add=0,max_num_images=None):\n",
    "    \"\"\"Load the data for a folder.\"\"\"\n",
    "    dataset= {}\n",
    "    dataset['height'] = []\n",
    "    dataset['label'] = []\n",
    "    dataset['left'] = []\n",
    "    dataset['top'] = []\n",
    "    dataset['width'] = []\n",
    "    dataset['image'] = []\n",
    "    \n",
    "    def print_attrs(name, obj):\n",
    "        vals = []\n",
    "        if obj.shape[0] == 1:\n",
    "            vals.append(obj[0][0])\n",
    "        else:\n",
    "            for k in range(obj.shape[0]):\n",
    "                vals.append(f[obj[k][0]][0][0])\n",
    "        dataset[name].append(vals)\n",
    "    \n",
    "    image_files = sorted([file_name for file_name in os.listdir(folder)\n",
    "                if file_name.endswith(\".png\")],\n",
    "                         key=lambda name:int(name[:-4]))\n",
    "    print ('first_images :')\n",
    "    print(image_files[:10])\n",
    "    total_images=len(image_files)\n",
    "    num_images=0\n",
    "    digitStruct_file = os.path.join(folder, \"digitStruct.mat\")\n",
    "    with h5py.File(digitStruct_file,\"r\") as f:\n",
    "        for item in f['/digitStruct/bbox']:\n",
    "            f[item[0]].visititems(print_attrs)\n",
    "            if num_images % 500 == 0:\n",
    "                percent=num_images*100/total_images\n",
    "                sys.stdout.write(\"%d%%\" % percent)\n",
    "                sys.stdout.flush()\n",
    "            elif num_images % 50 == 0:\n",
    "                sys.stdout.write(\".\")\n",
    "                sys.stdout.flush()\n",
    "            num_images=num_images+1\n",
    "            if max_num_images!=None and num_images>=max_num_images:\n",
    "                break\n",
    "    \n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                        (num_images, min_num_images))\n",
    "    \n",
    "    print('loaded %d images'% len(dataset[\"image\"]))\n",
    "    print(\"resizing, reshaping and multiplying images\")\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    def resize_and_add_image(label,image):\n",
    "        #apply gray scale\n",
    "        image= misc.imresize(image,(final_image_size, final_image_size))\n",
    "        image = np.dot(image, [[0.2989],[0.5870],[0.1140]])\n",
    "        mean = np.mean(image, dtype=np.float32)\n",
    "        std = np.std(image, dtype=np.float32, ddof=1)\n",
    "        if std < 1e-4: std = 1.\n",
    "        image = (image - mean) / std        \n",
    "        image=image.reshape(final_image_size, final_image_size,1)\n",
    "        \n",
    "        labels.append(label)\n",
    "        images.append(image)\n",
    "    \n",
    "    image_index=-1\n",
    "    num_images=0\n",
    "    for height,label,left,top,width in zip(\n",
    "        dataset['height'],dataset['label'],dataset['left'],dataset['top'],dataset['width']):\n",
    "        length=len(label)\n",
    "        for i in range(length):\n",
    "            if label[i]==blanc_label:\n",
    "                label[i]=0\n",
    "            while len(label)<max_labels:\n",
    "                label.append(blanc_label)\n",
    "        image_index = image_index+1\n",
    "        image_file = os.path.join(folder, image_files[image_index])        \n",
    "        try:\n",
    "            image = (ndimage.imread(image_file).astype(float) - \n",
    "                          pixel_depth / 2) / pixel_depth\n",
    "            resize_and_add_image(label,image)\n",
    "        except IOError as e:\n",
    "            print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n",
    "            continue\n",
    "        if to_add > 0:\n",
    "            #print(\"original image\")\n",
    "            #display_image(image)\n",
    "            #find out the minimum rectangle containing the digits            \n",
    "            min_left=image.shape[1]\n",
    "            min_top=image.shape[0]\n",
    "            max_right=0\n",
    "            max_bottom=0\n",
    "            #print(\"initial \",min_top,max_bottom,min_left,max_right)\n",
    "            for i in range(len(left)):\n",
    "                min_left=min_left if min_left<=left[i] else left[i]\n",
    "                min_top=min_top if min_top<=top[i] else top[i]\n",
    "                right=left[i]+width[i]\n",
    "                max_right=max_right if max_right>=right else right\n",
    "                bottom=top[i]+height[i]\n",
    "                max_bottom=max_bottom if max_bottom >= bottom else bottom\n",
    "                \n",
    "            #print(\"before expanding \",min_top,max_bottom,min_left,max_right)\n",
    "            \n",
    "            #expand the bounding box by 30%\n",
    "            ratio=.30\n",
    "            min_left,max_right=expand(min_left,max_right,ratio,image.shape[1])\n",
    "            min_top,max_bottom=expand(min_top,max_bottom,ratio,image.shape[0])\n",
    "            croped_image=image[min_top:max_bottom,min_left:max_right,:]            \n",
    "            #print(\"cropped by \",min_top,max_bottom,min_left,max_right)\n",
    "            #display_image(croped_image)\n",
    "            resized_crop=misc.imresize(croped_image,(image_size, image_size,num_channels))\n",
    "            size_diff=image_size-sub_image_size\n",
    "            new_tops=np.random.choice(size_diff,to_add,replace=False)\n",
    "            new_lefts=np.random.choice(size_diff,to_add,replace=False)\n",
    "            for new_top,new_left in zip(new_tops,new_lefts):\n",
    "                new_image=resized_crop[new_top:new_top+sub_image_size,new_left:new_left+sub_image_size,:]  \n",
    "                #print(\"new image \")\n",
    "                #display_image(new_image)\n",
    "                #TODO also ajust the heights,widths,lefts and tops information\n",
    "                resize_and_add_image(label,new_image)\n",
    "        \n",
    "        if image_index % 500 == 0:\n",
    "            percent=image_index*100/total_images\n",
    "            sys.stdout.write(\"%d%%\" % percent)\n",
    "            sys.stdout.flush()\n",
    "        elif image_index % 50 == 0:\n",
    "            sys.stdout.write(\".\")\n",
    "            sys.stdout.flush()\n",
    "        num_images+=1\n",
    "    \n",
    "    if num_images < min_num_images:\n",
    "        raise Exception('Many fewer images than expected: %d < %d' %\n",
    "                        (num_images, min_num_images))\n",
    "    #shuffle the data\n",
    "    to_shuffle=zip(labels,images)\n",
    "    np.random.shuffle(to_shuffle)\n",
    "    labels,images=tuple([list(l) for l in zip(*to_shuffle)])\n",
    "    #transorm image to np array\n",
    "    images=np.asanyarray(images,dtype=np.float32)\n",
    "    labels=np.asanyarray(labels,dtype=np.float32)\n",
    "    dataset['label'] = labels\n",
    "    dataset['image'] = images\n",
    "    \n",
    "    print(\"resized to %d: \"%len(images))\n",
    "    return dataset\n",
    "        \n",
    "def maybe_pickle(folder, min_num_images_per_class, force=False,to_add=0,max_num_images=None):\n",
    "    set_filename = folder + '.pickle'\n",
    "    if os.path.exists(set_filename) and not force:\n",
    "      # You may override by setting force=True.\n",
    "      print('%s already present - Skipping pickling.' % set_filename)\n",
    "    else:\n",
    "        print('Pickling %s.' % set_filename)\n",
    "        dataset = load_folder(folder, min_num_images_per_class,to_add=to_add,max_num_images=max_num_images)\n",
    "        with open(set_filename, 'wb') as f:\n",
    "            print(\"saving data to \",set_filename)\n",
    "            pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "    return set_filename\n",
    "\n",
    "train_datasets = maybe_pickle(train_folder, 32000,to_add=3) #add three new images for each train image\n",
    "test_datasets = maybe_pickle(test_folder, 12000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some labels and images to make sure that everything is loaded fine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_images(file_name,num_images=5):\n",
    "    print (\"showing some labels and images for %s\"%file_name)\n",
    "    with open(file_name, 'r') as f:\n",
    "        data=pickle.load(f)\n",
    "        labels=data[\"label\"]\n",
    "        total_images=len(labels)\n",
    "        images=data[\"image\"]\n",
    "        print(\"loaded %d images\"%total_images)\n",
    "        for i in np.random.choice(total_images,num_images,):\n",
    "            for j in range(i,i+5):\n",
    "                print(labels[j])\n",
    "                display_image(images[j].reshape(final_image_size,final_image_size))\n",
    "            \n",
    "display_images(train_datasets)\n",
    "#display_images(test_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
